{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks import SplitMNIST, SplitCIFAR10\n",
    "import lovely_tensors as lt\n",
    "from torchvision import transforms, datasets\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import shutup;\n",
    "import pytorch_lightning as pl\n",
    "import os \n",
    "from src.utils.shift_class_targets import shift_experiences_classes\n",
    "\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK']=\"1\"\n",
    "os.environ[\"WANDB_START_METHOD\"] = \"thread\"\n",
    "\n",
    "shutup.please()\n",
    "pl.seed_everything(42)\n",
    "lt.monkey_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "benchmark = SplitCIFAR10(\n",
    "    n_experiences=5,\n",
    "    return_task_id=True,\n",
    "    shuffle=False,\n",
    "    dataset_root='./datasets',\n",
    "    train_transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0))\n",
    "    ]),\n",
    "    eval_transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0))\n",
    "    ]),\n",
    ")\n",
    "shift_experiences_classes(benchmark, num_tasks_in_batch=2)\n",
    "\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root='./datasets',\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root='./datasets',\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0)),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import argparse\n",
    "from train_utils import get_device, add_arguments, get_wandb_params\n",
    "from src.vq_vae.init_scrips import get_model\n",
    "from src.utils.train_script import overwrite_config_with_args, parse_arguments\n",
    "from configparser import ConfigParser\n",
    "from src.vq_vae.configuration.config import TrainConfig\n",
    "\n",
    "ini_config = ConfigParser()\n",
    "ini_config.read(\"../src/vq_vae/configuration/train.ini\")\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Model trainer\")\n",
    "parser = add_arguments(parser)\n",
    "\n",
    "## Read args\n",
    "args = parse_arguments(parser)\n",
    "args.accelerator = \"mps\"\n",
    "args.train_logger = \"tensorboard\"\n",
    "args.evaluation_logger = \"int\"\n",
    "args.max_epochs = 300\n",
    "args.min_epochs = 300\n",
    "args.num_workers = 0\n",
    "args.regularization_dropout = 0.2\n",
    "args.regularization_lambda = 0.01\n",
    "args.learning_rate = 0.001\n",
    "args.batch_size = 32\n",
    "args.best_model_prefix = \"artifacts\"\n",
    "args.num_random_noise = 0\n",
    "args.model = \"vq-vae\"\n",
    "\n",
    "config = TrainConfig.construct_typed_config(ini_config)\n",
    "overwrite_config_with_args(args, config)\n",
    "\n",
    "is_using_wandb = (\n",
    "    config.train_logger == \"wandb\"\n",
    "    or config.evaluation_logger == \"wandb\"\n",
    "    or args.run_id\n",
    ")\n",
    "if is_using_wandb:\n",
    "    wandb_params = get_wandb_params(args, config)\n",
    "\n",
    "    wandb.run.name = args.experiment_name or (\n",
    "        f\"RI-0.\"\n",
    "        f\"RN-{config.num_random_noise}.\"\n",
    "        f\"Dr-{config.regularization_dropout}.\"\n",
    "        f\"Wd-{config.regularization_lambda}.\"\n",
    "    )\n",
    "    wandb_params[\"name\"] = wandb.run.name\n",
    "else:\n",
    "    wandb_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /Users/ewriji/Library/Caches/pypoetry/virtualenvs/rnd-ve5eq-PE-py3.10/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    }
   ],
   "source": [
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from train_utils import get_loggers\n",
    "from src.avalanche.strategies import NaivePytorchLightning\n",
    "from src.vq_vae.model.vq_vae import VQVae\n",
    "\n",
    "device = get_device(config)\n",
    "vq_vae_model = VQVae(\n",
    "    num_hiddens=config.num_hiddens,\n",
    "    num_residual_layers=config.num_residual_layers,\n",
    "    num_residual_hiddens=config.num_residual_hiddens,\n",
    "    num_embeddings=config.num_embeddings,\n",
    "    embedding_dim=config.embedding_dim,\n",
    "    commitment_cost=config.commitment_cost,\n",
    "    decay=config.decay,\n",
    "    learning_rate=config.learning_rate,\n",
    "    regularization_lambda=config.regularization_lambda,\n",
    "    regularization_dropout=config.regularization_dropout,\n",
    "    data_variance=0.06328692405746414,\n",
    "    use_lpips=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vq_vae.init_scrips import get_evaluation_plugin, get_callbacks\n",
    "\n",
    "train_experience, test_experience = next(iter(zip(benchmark.train_stream, benchmark.test_stream)))\n",
    "# Test trained model\n",
    "cl_strategy_logger, eval_plugin_loggers = get_loggers(config, vq_vae_model, wandb_params)\n",
    "evaluation_plugin = EvaluationPlugin(\n",
    "    suppress_warnings=True,\n",
    ")\n",
    "\n",
    "cl_strategy = NaivePytorchLightning(\n",
    "    accelerator=config.accelerator,\n",
    "    devices=config.devices,\n",
    "    validate_every_n=config.validate_every_n,\n",
    "    accumulate_grad_batches=config.accumulate_grad_batches,\n",
    "    train_logger=cl_strategy_logger,\n",
    "    initial_resume_from=args.resume_from,\n",
    "    model=vq_vae_model,\n",
    "    device=device,\n",
    "    optimizer=vq_vae_model.configure_optimizers(),\n",
    "    criterion=vq_vae_model.criterion,\n",
    "    train_mb_size=config.batch_size,\n",
    "    train_mb_num_workers=config.num_workers,\n",
    "    train_epochs=config.max_epochs,\n",
    "    eval_mb_size=config.batch_size,\n",
    "    evaluator=evaluation_plugin,\n",
    "    callbacks=get_callbacks(config),\n",
    "    max_epochs=config.max_epochs,\n",
    "    min_epochs=config.min_epochs,\n",
    "    best_model_path_prefix=config.best_model_prefix,\n",
    "    plugins=[],\n",
    ")\n",
    "\n",
    "# cl_strategy.train(train_experience, [test_experience])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_strategy.model is vq_vae_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd87cf25d5d4278a087eccedcbaf9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor 0.850\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test trained model\n",
    "test_dataset =  benchmark.test_stream[4].dataset\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "cl_strategy.model.eval()\n",
    "losses = []\n",
    "targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        x, y, *_ = batch\n",
    "        x, y = x.to(vq_vae_model.device), y.to(vq_vae_model.device)\n",
    "\n",
    "        z = vq_vae_model.encoder(x)\n",
    "        z = vq_vae_model.pre_vq_conv(z)\n",
    "        vq_loss, quantized, perplexity = vq_vae_model.vq_vae(z)\n",
    "        x_recon = vq_vae_model.decoder(quantized)\n",
    "\n",
    "        _, reconstruction_loss, clf_loss, clf_acc, _ = vq_vae_model.criterion(\n",
    "            (vq_loss, x_recon, quantized, x, perplexity, None), y\n",
    "        )\n",
    "        loss = vq_loss + reconstruction_loss\n",
    "\n",
    "        losses.append(loss)\n",
    "        targets.extend(y.tolist())\n",
    "\n",
    "avg_test_loss = torch.tensor(losses).mean()\n",
    "print(avg_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[256, 64, 1, 1] n=16384 x∈[-1.839, 1.535] μ=0.064 σ=0.717"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 64, 8, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from src.vq_vae.model.resnet import ResidualStack\n",
    "\n",
    "num_hiddens = 128\n",
    "num_residual_layers = 2\n",
    "num_residual_hiddens = 32\n",
    "regularization_dropout = 0.2\n",
    "\n",
    "_model = nn.Sequential(\n",
    "\n",
    "    # nn.Conv2d(\n",
    "    #     in_channels=64,\n",
    "    #     out_channels=num_hiddens,\n",
    "    #     kernel_size=3,\n",
    "    #     stride=1,\n",
    "    #     padding=1,\n",
    "    # ),\n",
    "    # ResidualStack(\n",
    "    #     in_channels=num_hiddens,\n",
    "    #     num_hiddens=num_hiddens,\n",
    "    #     num_residual_layers=num_residual_layers,\n",
    "    #     num_residual_hiddens=num_residual_hiddens,\n",
    "    #     regularization_dropout=regularization_dropout,\n",
    "    # ),\n",
    "    # nn.ConvTranspose2d(\n",
    "    #     in_channels=num_hiddens,\n",
    "    #     out_channels=num_hiddens,\n",
    "    #     kernel_size=4,\n",
    "    #     stride=2,\n",
    "    #     padding=1,\n",
    "    # ),\n",
    "    # nn.ReLU(),\n",
    "    # nn.ConvTranspose2d(\n",
    "    #     in_channels=num_hiddens,\n",
    "    #     out_channels=num_hiddens // 2,\n",
    "    #     kernel_size=4,\n",
    "    #     stride=2,\n",
    "    #     padding=1,\n",
    "    # ),\n",
    "    # nn.ReLU(),\n",
    "    # nn.ConvTranspose2d(\n",
    "    #     in_channels=num_hiddens // 2,\n",
    "    #     out_channels=3,\n",
    "    #     kernel_size=4,\n",
    "    #     stride=2,\n",
    "    #     padding=1,\n",
    "    # ),\n",
    ")\n",
    "\n",
    "_model(quantized).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.ConcatDataset at 0x3306ad750>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "ConcatDataset(\n",
    "    [experience.dataset for experience in benchmark.train_stream[: ]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c4163f40>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(test_dataset[0][0].permute(1, 2, 0).cpu() + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[64, 3, 4, 4] n=3072 x∈[-0.144, 0.144] μ=-0.001 σ=0.083\n",
      "tensor[64] x∈[-0.143, 0.129] μ=-0.003 σ=0.074\n",
      "tensor[128, 64, 4, 4] n=131072 x∈[-0.031, 0.031] μ=5.904e-05 σ=0.018\n",
      "tensor[128] x∈[-0.031, 0.031] μ=0.001 σ=0.016\n",
      "tensor[128, 128, 3, 3] n=147456 x∈[-0.029, 0.029] μ=-4.499e-05 σ=0.017\n",
      "tensor[128] x∈[-0.029, 0.028] μ=0.000 σ=0.017\n",
      "tensor[32, 128, 3, 3] n=36864 x∈[-0.029, 0.029] μ=-4.836e-05 σ=0.017\n",
      "tensor[128, 32, 1, 1] n=4096 x∈[-0.177, 0.177] μ=0.001 σ=0.102\n",
      "tensor[32, 128, 3, 3] n=36864 x∈[-0.029, 0.029] μ=-0.000 σ=0.017\n",
      "tensor[128, 32, 1, 1] n=4096 x∈[-0.177, 0.177] μ=0.001 σ=0.101\n",
      "tensor[64, 128, 1, 1] n=8192 x∈[-0.088, 0.088] μ=-0.001 σ=0.051\n",
      "tensor[64] x∈[-0.086, 0.086] μ=-0.000 σ=0.052\n",
      "tensor[512, 64] n=32768 x∈[-3.976, 4.122] μ=0.004 σ=0.996\n",
      "tensor[512, 64] n=32768 x∈[-3.907, 3.927] μ=-0.001 σ=1.003\n",
      "tensor[128, 64, 3, 3] n=73728 x∈[-0.042, 0.042] μ=0.000 σ=0.024\n",
      "tensor[128] x∈[-0.041, 0.041] μ=-0.001 σ=0.024\n",
      "tensor[32, 128, 3, 3] n=36864 x∈[-0.029, 0.029] μ=-4.161e-05 σ=0.017\n",
      "tensor[128, 32, 1, 1] n=4096 x∈[-0.177, 0.177] μ=0.003 σ=0.103\n",
      "tensor[32, 128, 3, 3] n=36864 x∈[-0.029, 0.029] μ=-9.201e-06 σ=0.017\n",
      "tensor[128, 32, 1, 1] n=4096 x∈[-0.177, 0.177] μ=-0.000 σ=0.104\n",
      "tensor[128, 64, 4, 4] n=131072 x∈[-0.031, 0.031] μ=-4.294e-05 σ=0.018\n",
      "tensor[64] x∈[-0.031, 0.030] μ=0.001 σ=0.017\n",
      "tensor[64, 3, 4, 4] n=3072 x∈[-0.144, 0.144] μ=0.000 σ=0.083\n",
      "tensor[3] x∈[0.069, 0.137] μ=0.114 σ=0.039 [0.135, 0.137, 0.069]\n"
     ]
    }
   ],
   "source": [
    "for param in vq_vae_model.cpu().parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCScenario"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(benchmark)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "5da7ba37bc5bdae9b513af7f05bf2924837c9a2f6b279cd0b39590e16ef5df98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
