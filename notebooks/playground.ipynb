{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks import SplitMNIST, SplitCIFAR10\n",
    "import lovely_tensors as lt\n",
    "from torchvision import transforms, datasets\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import shutup;\n",
    "import pytorch_lightning as pl\n",
    "import os \n",
    "\n",
    "\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK']=\"1\"\n",
    "shutup.please()\n",
    "pl.seed_everything(42)\n",
    "lt.monkey_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "benchmark = SplitCIFAR10(\n",
    "    n_experiences=5,\n",
    "    return_task_id=True,\n",
    "    shuffle=False,\n",
    "    dataset_root='./datasets',\n",
    "    train_transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0))\n",
    "    ]),\n",
    "    eval_transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0))\n",
    "    ]),\n",
    ")\n",
    "\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root='./datasets',\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root='./datasets',\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0)),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import argparse\n",
    "from train_utils import get_device, add_arguments, get_wandb_params\n",
    "from src.vq_vae.init_scrips import get_model\n",
    "from src.utils.train_script import overwrite_config_with_args, parse_arguments\n",
    "from configparser import ConfigParser\n",
    "from src.vq_vae.configuration.config import TrainConfig\n",
    "\n",
    "ini_config = ConfigParser()\n",
    "ini_config.read(\"../src/vq_vae/configuration/train.ini\")\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Model trainer\")\n",
    "parser = add_arguments(parser)\n",
    "\n",
    "## Read args\n",
    "args = parse_arguments(parser)\n",
    "args.accelerator = \"mps\"\n",
    "args.train_logger = \"int\"\n",
    "args.evaluation_logger = \"int\"\n",
    "args.max_epochs = 60\n",
    "args.min_epochs = 60\n",
    "args.num_workers = 0\n",
    "args.regularization_dropout = 0.2\n",
    "args.regularization_lambda = 0.01\n",
    "args.learning_rate = 0.0001\n",
    "args.batch_size = 256\n",
    "args.best_model_prefix = \"artifacts\"\n",
    "args.num_random_noise = 1000\n",
    "args.model = \"vq-vae\"\n",
    "\n",
    "config = TrainConfig.construct_typed_config(ini_config)\n",
    "overwrite_config_with_args(args, config)\n",
    "\n",
    "is_using_wandb = (\n",
    "    config.train_logger == \"wandb\"\n",
    "    or config.evaluation_logger == \"wandb\"\n",
    "    or args.run_id\n",
    ")\n",
    "if is_using_wandb:\n",
    "    wandb_params = get_wandb_params(args, config)\n",
    "\n",
    "    wandb.run.name = args.experiment_name or (\n",
    "        f\"RI-0.\"\n",
    "        f\"RN-{config.num_random_noise}.\"\n",
    "        f\"Dr-{config.regularization_dropout}.\"\n",
    "        f\"Wd-{config.regularization_lambda}.\"\n",
    "    )\n",
    "    wandb_params[\"name\"] = wandb.run.name\n",
    "else:\n",
    "    wandb_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from train_utils import get_loggers\n",
    "from src.avalanche.strategies import NaivePytorchLightning\n",
    "\n",
    "device = get_device(config)\n",
    "vq_vae_model = get_model(config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76be52ca79864472a822eea49d27cfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.vq_vae.init_scrips import get_evaluation_plugin, get_callbacks\n",
    "\n",
    "train_experience, test_experience = next(iter(zip(benchmark.train_stream, benchmark.test_stream)))\n",
    "# Test trained model\n",
    "cl_strategy_logger, eval_plugin_loggers = get_loggers(config, vq_vae_model, wandb_params)\n",
    "evaluation_plugin = EvaluationPlugin(\n",
    "    suppress_warnings=True,\n",
    ")\n",
    "\n",
    "cl_strategy = NaivePytorchLightning(\n",
    "    accelerator=config.accelerator,\n",
    "    devices=config.devices,\n",
    "    validate_every_n=config.validate_every_n,\n",
    "    accumulate_grad_batches=config.accumulate_grad_batches,\n",
    "    train_logger=cl_strategy_logger,\n",
    "    initial_resume_from=args.resume_from,\n",
    "    model=vq_vae_model,\n",
    "    device=device,\n",
    "    optimizer=vq_vae_model.configure_optimizers(),\n",
    "    criterion=vq_vae_model.criterion,\n",
    "    train_mb_size=config.batch_size,\n",
    "    train_mb_num_workers=config.num_workers,\n",
    "    train_epochs=config.max_epochs,\n",
    "    eval_mb_size=config.batch_size,\n",
    "    evaluator=evaluation_plugin,\n",
    "    callbacks=get_callbacks(config),\n",
    "    max_epochs=config.max_epochs,\n",
    "    min_epochs=config.min_epochs,\n",
    "    best_model_path_prefix=config.best_model_prefix,\n",
    "    plugins=[],\n",
    ")\n",
    "\n",
    "cl_strategy.train(train_experience, [test_experience])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test trained model\n",
    "test_dataset = test_experience.dataset\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "vq_vae_model.eval()\n",
    "losses = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        x, y, *_ = batch\n",
    "        x, y = x.to(vq_vae_model.device), y.to(vq_vae_model.device)\n",
    "\n",
    "        vq_loss, x_recon, quantized, _, perplexity, logits = vq_vae_model.forward(x)\n",
    "        _, reconstruction_loss, clf_loss, clf_acc, _ = vq_vae_model.criterion(\n",
    "            (vq_loss, x_recon, quantized, x, perplexity, logits), y\n",
    "        )\n",
    "        loss = vq_loss + reconstruction_loss\n",
    "        losses.append(loss)\n",
    "\n",
    "avg_test_loss = torch.tensor(losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(x_recon[0].permute(1, 2, 0) + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vq_vae_model.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "5da7ba37bc5bdae9b513af7f05bf2924837c9a2f6b279cd0b39590e16ef5df98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
