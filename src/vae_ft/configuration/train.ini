[training]
accelerator = gpu
devices = 0,
batch_size = 32
max_epochs = 300
min_epochs = 50
validate_every_n = 5
num_workers = 2
accumulate_grad_batches =
learning_rate = 0.001

[logging]
evaluation_logger = wandb
train_logger = wandb
logging_path = logs

[model]
input_dim = 784
z_dim = 2